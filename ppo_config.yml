Hopper-v3:
  normalize: true
  n_envs: 1
  policy: 'MlpPolicy'
  n_timesteps: !!float 1e6
  batch_size: 32
  n_steps: 512
  gamma: 0.999
  learning_rate: 9.80828e-05
  ent_coef: 0.00229519
  clip_range: 0.2
  n_epochs: 5
  gae_lambda: 0.99
  max_grad_norm: 0.7
  vf_coef: 0.835671
  policy_kwargs: "dict(
                    log_std_init=-2,
                    ortho_init=False,
                    activation_fn=nn.ReLU,
                    net_arch=[dict(pi=[256, 256], vf=[256, 256])]
                  )"


Hopper-v3:
  learning_rate: 0.0003
  batch_size: 64
  n_steps: 1024
  verbose: 1
  seed: 101
  policy: 'MlpPolicy'


Gail1:
  demo_batch_size: 20000
  gen_train_timesteps: 20000
  lr: !!float 1e-3
  ts: !!float 3e6
  round: 1
  wd: !!float 0

Gail2:
  demo_batch_size: 20000
  gen_train_timesteps: 40000
  lr: !!float 1e-3
  ts: !!float 3e6
  round: 1
  wd: !!float 0

Gail3:
  demo_batch_size: 20000
  gen_train_timesteps: 20000
  lr: !!float 1e-3
  ts: !!float 3e6
  round: 2
  wd: !!float 0

Gail4:
  demo_batch_size: 20000
  gen_train_timesteps: 40000
  lr: !!float 1e-3
  ts: !!float 3e6
  round: 2
  wd: !!float 0

Gail5:
  demo_batch_size: 1024
  gen_train_timesteps: 20000
  lr: !!float 1e-3
  ts: !!float 3e6
  round: 2
  wd: !!float 0

Gail6:
  demo_batch_size: 1024
  gen_train_timesteps: 1024
  lr: !!float 1e-3
  ts: !!float 3e6
  round: 2
  wd: !!float 0

  # bs=256
ppo1:
  n_envs: 16
  n_timesteps: !!float 3e6
  learning_rate: !!float 0.0003
  batch_size: 256
  n_steps: 8000
  policy: 'MlpPolicy'
  verbose: 1

# bs=1024
ppo2:
  n_envs: 16
  n_timesteps: !!float 3e6
  learning_rate: !!float 0.0003
  batch_size: 1024
  n_steps: 8000
  policy: 'MlpPolicy'
  verbose: 1

# bs=256,n_steps =16000  
ppo3:
  n_envs: 16
  n_timesteps: !!float 3e6
  learning_rate: !!float 0.0003
  batch_size: 256
  n_steps: 16000
  policy: 'MlpPolicy'
  verbose: 1

# bs=1024,n_steps =16000  
ppo4:
  n_envs: 16
  n_timesteps: !!float 3e6
  learning_rate: !!float 0.0003
  batch_size: 1024
  n_steps: 16000
  policy: 'MlpPolicy'
  verbose: 1

# bs=256,n_steps =1024  
ppo5:
  n_envs: 16
  n_timesteps: !!float 3e6
  learning_rate: !!float 0.0003
  batch_size: 256
  n_steps: 1024
  policy: 'MlpPolicy'
  verbose: 1

CartPole-v1:
  n_envs: 1
  n_timesteps: !!float 1e5
  policy: 'MlpPolicy'
  n_steps: 256
  batch_size: 256
  learning_rate: !!float 0.001
  verbose: 1